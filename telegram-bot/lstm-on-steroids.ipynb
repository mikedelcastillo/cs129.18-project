{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk.corpus import stopwords\n",
    "np.random.seed(1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only' 'y' 'by' 'am' 'most' 'me' 'same' 'these' 'so' 'some' 'why' 'down'\n",
      " 'had' 'd' 'at' 'having' 'those' 'has' 'few' 'theirs' \"you've\" 'more' 'i'\n",
      " 'than' 'through' 'be' 'what' 'where' 'myself' 'which' 'doing' 'ours'\n",
      " 'will' 'in' 'both' 'do' 'it' 'o' 'on' 'yours' 'once' 'ourselves' 'here'\n",
      " 'about' \"it's\" 'my' 'for' 'her' 'then' 'after' \"should've\" 'from' 'each'\n",
      " 'when' 'does' 'now' 'off' 'don' 'are' 'we' 'itself' 'should' 'his'\n",
      " 'between' 'our' 'were' 'under' 'other' 'all' 'she' 'won' 'been' \"you're\"\n",
      " 'how' 'did' 'yourself' 'they' 'into' 'there' 've' 'such' 't' 's' 'and'\n",
      " 'over' 'to' 'just' 'was' 'being' 'because' 'if' 'who' 'further' 'the'\n",
      " 'any' \"that'll\" 'themselves' 'as' 'again' \"you'd\" 'until' 'he' 'him'\n",
      " 'this' 'or' 'of' 'below' 'an' \"she's\" 'weren' 'm' 'their' 'ma' 'up' 'll'\n",
      " 'whom' 'hers' 'can' 'you' 'them' 'very' 'a' 'herself' 'before' 'too'\n",
      " 'himself' 'during' 're' 'out' 'its' 'above' 'own' 'have' 'while'\n",
      " 'yourselves' 'that' 'with' \"you'll\" 'is' 'your']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "stop_words = pd.read_csv('../data/stopwords.csv')['words'].values\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    word_tokens = text_to_word_sequence(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([pd.read_csv(x) for x in [\n",
    "    '../data/tweets.csv',\n",
    "    '../data/word-list.csv',\n",
    "    '../data/twitter-airline-sentiment.csv',\n",
    "    '../data/sentiwordnet.csv',\n",
    "    '../data/reviews.csv',\n",
    "    '../data/imdb.csv',\n",
    "\n",
    "]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = list(map(remove_stop_words, data['text'].values))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text'].values\n",
    "corpus = [text_to_word_sequence(y) for y in sentences]\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_train, X_raw_test, Y_train, Y_test = train_test_split(\n",
    "    sentences,\n",
    "    data[['pos', 'neg']].values,\n",
    "    test_size=0.2, \n",
    "    random_state=3945\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 35\n",
    "vector_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import os\n",
    "\n",
    "# word2vec = KeyedVectors.load_word2vec_format('../../GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "word2vec_name = 'lstm-word2vec.bin'\n",
    "\n",
    "# Create Word2Vec\n",
    "if os.path.isfile(word2vec_name): \n",
    "    print(\"Loading...\")\n",
    "    word2vec = KeyedVectors.load(word2vec_name)\n",
    "\n",
    "else:\n",
    "    print(\"Computing...\")\n",
    "    word2vec = Word2Vec(sentences=corpus,\n",
    "                    size=vector_size, \n",
    "                    window=10, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=4)\n",
    "    word2vec.save(word2vec_name)\n",
    "\n",
    "word2vec = word2vec.wv\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2index(corpus):\n",
    "    gc.collect()\n",
    "    input_matrix = np.zeros((len(corpus),max_sentence_length))\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        for t, token in enumerate(corpus[i]):\n",
    "            if t >= max_sentence_length:\n",
    "                break\n",
    "            if token not in word2vec.vocab:\n",
    "                continue\n",
    "            input_matrix[i, t] = word2vec.vocab.get(token).index\n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sent2index(X_raw_train)\n",
    "X_test = sent2index(X_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "vocab_len = len(word2vec.vocab) + 1\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, vector_size))\n",
    "\n",
    "for word in word2vec.vocab:\n",
    "    index = word2vec.vocab.get(word).index\n",
    "    emb_matrix[index, :] = word2vec[word]\n",
    "    \n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "sentence_indices = Input(shape=(max_sentence_length,))\n",
    "    \n",
    "embedding_layer = Embedding(vocab_len, vector_size, trainable = False)\n",
    "embedding_layer.build((None,))\n",
    "embedding_layer.set_weights([emb_matrix])\n",
    "\n",
    "embeddings = embedding_layer(sentence_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = LSTM(128, return_sequences=True)(embeddings)\n",
    "X = Dropout(0.5)(X)\n",
    "X = LSTM(128, return_sequences=False)(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Dense(2, activation=None)(X)\n",
    "X = Activation('softmax')(X)\n",
    "\n",
    "model = Model(inputs=[sentence_indices], outputs=X)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"keras-model.h5\"\n",
    "\n",
    "def compile_model():\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "def train_model(): \n",
    "    model.fit(\n",
    "        X_train, \n",
    "        y=Y_train, \n",
    "        batch_size=512, \n",
    "        epochs=100, \n",
    "        verbose=1, \n",
    "        validation_data=(X_test, Y_test))\n",
    "    \n",
    "    print(\"Saving model\")\n",
    "    model.save_weights(model_file)\n",
    "\n",
    "def load_model():\n",
    "    model.load_weights(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_train = True\n",
    "import os\n",
    "\n",
    "if os.path.isfile(model_file) and not force_train:\n",
    "    print(\"Loading model...\")\n",
    "    load_model()\n",
    "    compile_model()\n",
    "else:\n",
    "    print(\"Training model...\")\n",
    "    compile_model()\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mess = np.array([\n",
    "    'this is slow',\n",
    "    'this is exceptional service',\n",
    "])\n",
    "X_test_indices = sent2index(mess)\n",
    "pred = model.predict(X_test_indices)\n",
    "\n",
    "output = ''\n",
    "for i ,m in enumerate(mess):\n",
    "        output += ('{} {} {}\\n'.format('POSITIVE:' if pred[i][0] > 0.5 else 'NEGATIVE:', m, pred[i]))\n",
    "\n",
    "        \n",
    "print(output)\n",
    "        \n",
    "del mess\n",
    "del output\n",
    "del pred\n",
    "del X_test_indices\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "import urllib, json\n",
    "import urllib.request\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "TLGRM_SECRET = os.getenv('TLGRM_SECRET')\n",
    "TLGRM_MIKE = os.getenv('TLGRM_MIKE')\n",
    "\n",
    "def telegram_call(method, query = {}):\n",
    "    try:\n",
    "        url = 'http://api.telegram.org/bot{}/{}?{}'.format(TLGRM_SECRET, method, urllib.parse.urlencode(query))\n",
    "        response = urllib.request.urlopen(url)\n",
    "        return json.loads(response.read().decode(\"utf-8\"))\n",
    "    except:\n",
    "        print('Repeating call...')\n",
    "        return telegram_call(method, query)\n",
    "\n",
    "def telegram_bot(respond):\n",
    "    last_offset = 0\n",
    "    \n",
    "    while True:\n",
    "        data = telegram_call('getupdates', {'offset': last_offset})\n",
    "        for item in data['result']:\n",
    "            last_offset = item['update_id'] + 1\n",
    "            if 'message' in item:\n",
    "                if 'text' in item['message']:\n",
    "                    text = item['message']['text']\n",
    "                    chat_id = item['message']['chat']['id']\n",
    "                    response = respond(text)\n",
    "                    smd = telegram_call('sendmessage', {\n",
    "                        'chat_id': chat_id,\n",
    "                        'text': response\n",
    "                    })\n",
    "                    \n",
    "                    while smd['ok'] == False:\n",
    "                        smd = telegram_call('sendmessage', {\n",
    "                            'chat_id': chat_id,\n",
    "                            'text': response\n",
    "                        })\n",
    "                        \n",
    "                    clear_output()\n",
    "                    print('FROM: {}\\nSAYS: {}\\nRESPONSE: {}\\n\\n'.format(chat_id, text, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "gc.collect()\n",
    "\n",
    "uhms = [\n",
    "    \"uhm\", \"uhh\", \"hmm\", \n",
    "    \"hmmm\", \"oh uh\", \"oh hmm\",\n",
    "]\n",
    "\n",
    "sentiment = [\n",
    "    \"üò≠\",\n",
    "    \"‚òπÔ∏è\",\n",
    "    \"üòê\",\n",
    "    \"üôÇ\",\n",
    "    \"üòç\",\n",
    "]\n",
    "\n",
    "def respond(text):\n",
    "    mess = np.array([text])\n",
    "    X_test_indices = sent2index(mess)\n",
    "    pred = model.predict(X_test_indices)\n",
    "    score = pred[0][0]\n",
    "    sent = sentiment[floor(score * 5)]\n",
    "    response = '{}\\n\\n{}'.format(text, sent)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot(respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
