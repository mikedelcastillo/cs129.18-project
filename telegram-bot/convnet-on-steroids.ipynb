{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "import os.path\n",
    "import gc\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only' 'y' 'by' 'am' 'most' 'me' 'same' 'these' 'so' 'some' 'why' 'down'\n",
      " 'had' 'd' 'at' 'having' 'those' 'has' 'few' 'theirs' \"you've\" 'more' 'i'\n",
      " 'than' 'through' 'be' 'what' 'where' 'myself' 'which' 'doing' 'ours'\n",
      " 'will' 'in' 'both' 'do' 'it' 'o' 'on' 'yours' 'once' 'ourselves' 'here'\n",
      " 'about' \"it's\" 'my' 'for' 'her' 'then' 'after' \"should've\" 'from' 'each'\n",
      " 'when' 'does' 'now' 'off' 'don' 'are' 'we' 'itself' 'should' 'his'\n",
      " 'between' 'our' 'were' 'under' 'other' 'all' 'she' 'won' 'been' \"you're\"\n",
      " 'how' 'did' 'yourself' 'they' 'into' 'there' 've' 'such' 't' 's' 'and'\n",
      " 'over' 'to' 'just' 'was' 'being' 'because' 'if' 'who' 'further' 'the'\n",
      " 'any' \"that'll\" 'themselves' 'as' 'again' \"you'd\" 'until' 'he' 'him'\n",
      " 'this' 'or' 'of' 'below' 'an' \"she's\" 'weren' 'm' 'their' 'ma' 'up' 'll'\n",
      " 'whom' 'hers' 'can' 'you' 'them' 'very' 'a' 'herself' 'before' 'too'\n",
      " 'himself' 'during' 're' 'out' 'its' 'above' 'own' 'have' 'while'\n",
      " 'yourselves' 'that' 'with' \"you'll\" 'is' 'your']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "stop_words = pd.read_csv('../data/stopwords.csv')['words'].values\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    word_tokens = text_to_word_sequence(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        inter_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        allow_soft_placement=True, \n",
    "                        device_count = {'CPU' : 1, \n",
    "                                        'GPU' : 1 if use_gpu else 0})\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/twitter-airline-sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials experience tacky</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>didnt today must mean need take another trip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos  neg\n",
       "0                                               said  0.0  0.0\n",
       "1      plus youve added commercials experience tacky  1.0  0.0\n",
       "2       didnt today must mean need take another trip  0.0  0.0\n",
       "3  really aggressive blast obnoxious entertainmen...  0.0  1.0\n",
       "4                               really big bad thing  0.0  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = list(map(remove_stop_words, data['text'].values))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 13871\n"
     ]
    }
   ],
   "source": [
    "corpus = [text_to_word_sequence(y) for y in [x[0] for x in data[['text']].values]]\n",
    "labels = [np.array(x[[0, 1]]) for x in data[['pos', 'neg']].values]\n",
    "    \n",
    "print('Corpus size: {}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 35\n",
    "vector_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec = Word2Vec(sentences=corpus,\n",
    "                    size=vector_size, \n",
    "                    window=10, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=multiprocessing.cpu_count())\n",
    "\n",
    "vecs_x = word2vec.wv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_vec_data(corpus):\n",
    "    gc.collect()\n",
    "    input_matrix = np.zeros((len(corpus), max_sentence_length, vector_size), dtype=K.floatx())\n",
    "    for i in range(len(corpus)):\n",
    "        for t, token in enumerate(corpus[i]):\n",
    "            if t >= max_sentence_length:\n",
    "                break\n",
    "            if token not in vecs_x:\n",
    "                continue\n",
    "            input_matrix[i, t, :] = vecs_x[token]\n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras convolutional model\n",
    "gc.collect()\n",
    "batch_size = 32\n",
    "nb_epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same', input_shape=(max_sentence_length, vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11096 samples, validate on 2775 samples\n",
      "Epoch 1/20\n",
      "11096/11096 [==============================] - 50s 5ms/step - loss: 0.2777 - acc: 0.7095 - val_loss: 0.2242 - val_acc: 0.7276\n",
      "Epoch 2/20\n",
      "11096/11096 [==============================] - 26s 2ms/step - loss: 0.2205 - acc: 0.7456 - val_loss: 0.2139 - val_acc: 0.7319\n",
      "Epoch 3/20\n",
      "11096/11096 [==============================] - 34s 3ms/step - loss: 0.2106 - acc: 0.7503 - val_loss: 0.2121 - val_acc: 0.7452\n",
      "Epoch 4/20\n",
      "11096/11096 [==============================] - 33s 3ms/step - loss: 0.1989 - acc: 0.7534 - val_loss: 0.2134 - val_acc: 0.7431\n",
      "Epoch 5/20\n",
      "11096/11096 [==============================] - 32s 3ms/step - loss: 0.1892 - acc: 0.7586 - val_loss: 0.2136 - val_acc: 0.7409\n",
      "Epoch 6/20\n",
      "11096/11096 [==============================] - 38s 3ms/step - loss: 0.1839 - acc: 0.7605 - val_loss: 0.2160 - val_acc: 0.7416\n",
      "Epoch 7/20\n",
      "11096/11096 [==============================] - 28s 3ms/step - loss: 0.1723 - acc: 0.7660 - val_loss: 0.2214 - val_acc: 0.7369\n",
      "Epoch 8/20\n",
      "11096/11096 [==============================] - 38s 3ms/step - loss: 0.1635 - acc: 0.7731 - val_loss: 0.2230 - val_acc: 0.7384\n",
      "Epoch 9/20\n",
      "11096/11096 [==============================] - 37s 3ms/step - loss: 0.1575 - acc: 0.7784 - val_loss: 0.2316 - val_acc: 0.7431\n",
      "Epoch 10/20\n",
      "11096/11096 [==============================] - 36s 3ms/step - loss: 0.1474 - acc: 0.7806 - val_loss: 0.2484 - val_acc: 0.7377\n",
      "Epoch 11/20\n",
      "11096/11096 [==============================] - 33s 3ms/step - loss: 0.1425 - acc: 0.7820 - val_loss: 0.2467 - val_acc: 0.7438\n",
      "Epoch 12/20\n",
      "11096/11096 [==============================] - 26s 2ms/step - loss: 0.1372 - acc: 0.7882 - val_loss: 0.2410 - val_acc: 0.7405\n",
      "Epoch 13/20\n",
      "11096/11096 [==============================] - 32s 3ms/step - loss: 0.1307 - acc: 0.7871 - val_loss: 0.2545 - val_acc: 0.7301\n",
      "Epoch 14/20\n",
      "11096/11096 [==============================] - 39s 4ms/step - loss: 0.1249 - acc: 0.7902 - val_loss: 0.2636 - val_acc: 0.7283\n",
      "Epoch 15/20\n",
      "11096/11096 [==============================] - 24s 2ms/step - loss: 0.1158 - acc: 0.7955 - val_loss: 0.2639 - val_acc: 0.7272\n",
      "Epoch 16/20\n",
      "11096/11096 [==============================] - 22s 2ms/step - loss: 0.1094 - acc: 0.7979 - val_loss: 0.2765 - val_acc: 0.7337\n",
      "Epoch 17/20\n",
      "11096/11096 [==============================] - 24s 2ms/step - loss: 0.1084 - acc: 0.7995 - val_loss: 0.2908 - val_acc: 0.7268\n",
      "Epoch 18/20\n",
      "11096/11096 [==============================] - 21s 2ms/step - loss: 0.0980 - acc: 0.8016 - val_loss: 0.2984 - val_acc: 0.7272\n",
      "Epoch 19/20\n",
      "11096/11096 [==============================] - 22s 2ms/step - loss: 0.0918 - acc: 0.8059 - val_loss: 0.3190 - val_acc: 0.7333\n",
      "Epoch 20/20\n",
      "11096/11096 [==============================] - 26s 2ms/step - loss: 0.0892 - acc: 0.8064 - val_loss: 0.3267 - val_acc: 0.7268\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "            pad_vec_data(corpus), \n",
    "            labels, \n",
    "            test_size=0.2, \n",
    "            random_state=3945)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "gc.collect()\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True,\n",
    "          epochs=nb_epochs,\n",
    "          validation_data=(test_x, test_y),\n",
    "#                   verbose=0,\n",
    "          callbacks=[\n",
    "#                       EarlyStopping(min_delta=0.000025, patience=10),\n",
    "          ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE: hello there, my name is mike [0.08045997 0.91954005]\n",
      "NEGATIVE: not something i wanted to happen but i think i need to add more words for it to see [1.676564e-04 9.998323e-01]\n",
      "NEGATIVE: this was something i wanted i'm grateful for this app and i am looking forward to more things from you guys [0.49123523 0.5087648 ]\n",
      "POSITIVE: i don't fucking like you man [0.53060985 0.46939024]\n",
      "POSITIVE: considering how the usual process for this is tedious, having an app like this solves a lot of problems [0.9199988  0.08000121]\n",
      "POSITIVE: thank you that was some wonderful service that really helped me get from point A to point B [0.9868998  0.01310019]\n",
      "POSITIVE: this is amazing and was able to shorten the amount of time i needed to take to achieve this [0.94565856 0.05434138]\n",
      "NEGATIVE: this is nothing short of amazing, I cannot believe it [0.07906301 0.920937  ]\n",
      "NEGATIVE: how are you [0.2041254 0.7958746]\n",
      "NEGATIVE: i really like you [0.00479404 0.99520594]\n",
      "NEGATIVE: i don't actually like this product! [0.02806232 0.9719377 ]\n",
      "NEGATIVE: it's useless if you can't use it! [0.42579144 0.57420856]\n",
      "NEGATIVE: i can't believe i never heard of this [0.01871253 0.98128754]\n",
      "POSITIVE: this is awesome, didn't know I needed this [0.50473005 0.49526995]\n",
      "NEGATIVE: so what am i supposed to use this for? [0.31037816 0.6896218 ]\n",
      "NEGATIVE: what do I need this for? [0.04327029 0.9567297 ]\n",
      "POSITIVE: this is good [0.8482185 0.1517815]\n",
      "NEGATIVE: this is not good [0.24685194 0.753148  ]\n",
      "NEGATIVE: although the movie was great, it lacked impact [0.28531358 0.71468645]\n",
      "NEGATIVE: the movie wasnt that nice [0.38174763 0.61825234]\n",
      "NEGATIVE: the movie was nice [0.00744833 0.9925517 ]\n",
      "NEGATIVE: this is not acceptable, I lost everything using your app [0.0036957 0.9963043]\n",
      "POSITIVE: that was kinda stupid [0.685419 0.314581]\n",
      "POSITIVE: the instructions were unlear and is not friendly for non-techy people [0.7097181  0.29028198]\n",
      "NEGATIVE: this is really useful i would definitely tell everyone about it [0.09721126 0.9027887 ]\n",
      "NEGATIVE: i need to try this! [0.06753039 0.93246967]\n",
      "NEGATIVE: which is your favourite harry potter filmsorcerers stonechamber of secretsprisoner of azkabangoblet of firei like them all equallyi hate harry potter and think this is a stupid question [0.13728975 0.86271024]\n",
      "NEGATIVE: sitting in the third row of the imax cinema at sydney s darling harbour  but i sometimes felt as though i was in the tiny two seater plane that carried the giant camera around australia  sweeping and gliding  banking and hovering over some of the most not [0.12058149 0.87941855]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mess = [\n",
    "    \"hello there, my name is mike\",\n",
    "    \"not something i wanted to happen but i think i need to add more words for it to see\",\n",
    "    \"this was something i wanted i'm grateful for this app and i am looking forward to more things from you guys\",\n",
    "    \"i don't fucking like you man\",\n",
    "    \"considering how the usual process for this is tedious, having an app like this solves a lot of problems\",\n",
    "    \"thank you that was some wonderful service that really helped me get from point A to point B\",\n",
    "    \"this is amazing and was able to shorten the amount of time i needed to take to achieve this\",\n",
    "    \"this is nothing short of amazing, I cannot believe it\",\n",
    "    \"how are you\",\n",
    "    \"i really like you\",\n",
    "    \"i don't actually like this product!\",\n",
    "    \"it's useless if you can't use it!\",\n",
    "    \"i can't believe i never heard of this\",\n",
    "    \"this is awesome, didn't know I needed this\",\n",
    "    \"so what am i supposed to use this for?\",\n",
    "    \"what do I need this for?\",\n",
    "    \"this is good\",\n",
    "    \"this is not good\",\n",
    "    \"although the movie was great, it lacked impact\",\n",
    "    \"the movie wasnt that nice\",\n",
    "    \"the movie was nice\",\n",
    "    \"this is not acceptable, I lost everything using your app\",\n",
    "    \"that was kinda stupid\",\n",
    "    \"the instructions were unlear and is not friendly for non-techy people\",\n",
    "    \"this is really useful i would definitely tell everyone about it\",\n",
    "    \"i need to try this!\",\n",
    "    \"which is your favourite harry potter filmsorcerers stonechamber of secretsprisoner of azkabangoblet of firei like them all equallyi hate harry potter and think this is a stupid question\",\n",
    "    \"sitting in the third row of the imax cinema at sydney s darling harbour  but i sometimes felt as though i was in the tiny two seater plane that carried the giant camera around australia  sweeping and gliding  banking and hovering over some of the most not\",\n",
    "]\n",
    "\n",
    "pred = model.predict(pad_vec_data(list(map(remove_stop_words, mess))))\n",
    "output = ''\n",
    "\n",
    "for i ,m in enumerate(mess):\n",
    "    output += ('{} {} {}\\n'.format('POSITIVE:' if pred[i][0] > 0.5 else 'NEGATIVE:', m, pred[i]))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
