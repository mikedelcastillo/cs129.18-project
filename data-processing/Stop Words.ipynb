{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    " \n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only', 'y', 'by', 'am', 'most', 'me', 'same', 'these', 'so', 'some', 'why', 'down', 'had', 'd', 'at', 'having', 'those', 'has', 'few', 'theirs', \"you've\", 'more', 'i', 'than', 'through', 'be', 'what', 'where', 'myself', 'which', 'doing', 'ours', 'will', 'in', 'both', 'do', 'it', 'o', 'on', 'yours', 'once', 'ourselves', 'here', 'about', \"it's\", 'my', 'for', 'her', 'then', 'after', \"should've\", 'from', 'each', 'when', 'does', 'now', 'off', 'don', 'are', 'we', 'itself', 'should', 'his', 'between', 'our', 'were', 'under', 'other', 'all', 'she', 'won', 'been', \"you're\", 'how', 'did', 'yourself', 'they', 'into', 'there', 've', 'such', 't', 's', 'and', 'over', 'to', 'just', 'was', 'being', 'because', 'if', 'who', 'further', 'the', 'any', \"that'll\", 'themselves', 'as', 'again', \"you'd\", 'until', 'he', 'him', 'this', 'or', 'of', 'below', 'an', \"she's\", 'weren', 'm', 'their', 'ma', 'up', 'll', 'whom', 'hers', 'can', 'you', 'them', 'very', 'a', 'herself', 'before', 'too', 'himself', 'during', 're', 'out', 'its', 'above', 'own', 'have', 'while', 'yourselves', 'that', 'with', \"you'll\", 'is', 'your']\n"
     ]
    }
   ],
   "source": [
    "whitelist = [\n",
    "    'wouldn', \"wouldn't\",\n",
    "    \n",
    "    \"needn't\", \"needn\",\n",
    "    'couldn', \"couldn't\",\n",
    "    \n",
    "    'didn',\n",
    "    'aren',\n",
    "    \"isn't\",\n",
    "    \"shan't\",\n",
    "    \"haven't\",\n",
    "\n",
    "    'hasn',\n",
    "    'shan',\n",
    "    \"mightn't\",\n",
    "    \"hadn't\",\n",
    "    'wasn',\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'not', \"won't\"\n",
    "    \"hasn't\",\n",
    "    \"aren't\",\n",
    "    'haven',\n",
    "    'mustn',\n",
    "    \"doesn't\",\n",
    "    \"wasn't\",\n",
    "\n",
    "    \"nor\",\n",
    "    \"mustn't\",\n",
    "    \"ain\",\n",
    "    \"against\",\n",
    "    \"isn\",\n",
    "    \"no\",\n",
    "    \"didn't\",\n",
    "    \"hadn\",\n",
    "    \"hasn't\",\n",
    "\n",
    "    \"weren't\",\n",
    "    \"don't\",\n",
    "    \"won't\",\n",
    "    \"doesn\",\n",
    "    \"but\",\n",
    "    \"mightn\",\n",
    "]\n",
    "\n",
    "filtered_stop_words = [w for w in stop_words if not w in whitelist]\n",
    "print(filtered_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(data=filtered_stop_words)\n",
    "df.columns = ['words']\n",
    "df.to_csv('../data/stopwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only' 'y' 'by' 'am' 'most' 'me' 'same' 'these' 'so' 'some' 'why' 'down'\n",
      " 'had' 'd' 'at' 'having' 'those' 'has' 'few' 'theirs' \"you've\" 'more' 'i'\n",
      " 'than' 'through' 'be' 'what' 'where' 'myself' 'which' 'doing' 'ours'\n",
      " 'will' 'in' 'both' 'do' 'it' 'o' 'on' 'yours' 'once' 'ourselves' 'here'\n",
      " 'about' \"it's\" 'my' 'for' 'her' 'then' 'after' \"should've\" 'from' 'each'\n",
      " 'when' 'does' 'now' 'off' 'don' 'are' 'we' 'itself' 'should' 'his'\n",
      " 'between' 'our' 'were' 'under' 'other' 'all' 'she' 'won' 'been' \"you're\"\n",
      " 'how' 'did' 'yourself' 'they' 'into' 'there' 've' 'such' 't' 's' 'and'\n",
      " 'over' 'to' 'just' 'was' 'being' 'because' 'if' 'who' 'further' 'the'\n",
      " 'any' \"that'll\" 'themselves' 'as' 'again' \"you'd\" 'until' 'he' 'him'\n",
      " 'this' 'or' 'of' 'below' 'an' \"she's\" 'weren' 'm' 'their' 'ma' 'up' 'll'\n",
      " 'whom' 'hers' 'can' 'you' 'them' 'very' 'a' 'herself' 'before' 'too'\n",
      " 'himself' 'during' 're' 'out' 'its' 'above' 'own' 'have' 'while'\n",
      " 'yourselves' 'that' 'with' \"you'll\" 'is' 'your']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "stop_words = pd.read_csv('../data/stopwords.csv')['words'].values\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    word_tokens = text_to_word_sequence(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trying see not work but think might'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words('trying to see if this will not work but i think it might!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
