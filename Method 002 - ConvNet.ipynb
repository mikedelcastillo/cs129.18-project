{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "import os.path\n",
    "import gc\n",
    "\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mike del\n",
      "[nltk_data]     Castillo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Mike del\n",
      "[nltk_data]     Castillo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    " \n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_stop_words(text):\n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        inter_op_parallelism_threads=multiprocessing.cpu_count(), \n",
    "                        allow_soft_placement=True, \n",
    "                        device_count = {'CPU' : 1, \n",
    "                                        'GPU' : 1 if use_gpu else 0})\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/twitter-airline-sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials experience tacky</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>didnt today must mean need take another trip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos  neg\n",
       "0                                               said  0.0  0.0\n",
       "1      plus youve added commercials experience tacky  1.0  0.0\n",
       "2       didnt today must mean need take another trip  0.0  0.0\n",
       "3  really aggressive blast obnoxious entertainmen...  0.0  1.0\n",
       "4                               really big bad thing  0.0  1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = list(map(remove_stop_words, data['text'].values))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 13871\n"
     ]
    }
   ],
   "source": [
    "corpus = [text_to_word_sequence(y) for y in [x[0] for x in data[['text']].values]]\n",
    "labels = [np.array(x[[0, 1]]) for x in data[['pos', 'neg']].values]\n",
    "    \n",
    "print('Corpus size: {}'.format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 35\n",
    "vector_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec = Word2Vec(sentences=corpus,\n",
    "                    size=vector_size, \n",
    "                    window=10, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=multiprocessing.cpu_count())\n",
    "\n",
    "vecs_x = word2vec.wv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_vec_data(corpus):\n",
    "    gc.collect()\n",
    "    input_matrix = np.zeros((len(corpus), max_sent_length, vector_size), dtype=K.floatx())\n",
    "    for i in range(len(corpus)):\n",
    "        for t, token in enumerate(corpus[i]):\n",
    "            if t >= max_sent_length:\n",
    "                break\n",
    "            if token not in vecs_x:\n",
    "                continue\n",
    "            input_matrix[i, t, :] = vecs_x[token]\n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras convolutional model\n",
    "gc.collect()\n",
    "batch_size = 16\n",
    "nb_epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same', input_shape=(max_sentence_length, vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=2, activation='elu', padding='same'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10403 samples, validate on 3468 samples\n",
      "Epoch 1/20\n",
      "10403/10403 [==============================] - 8s 724us/step - loss: 0.2771 - acc: 0.7115 - val_loss: 0.2116 - val_acc: 0.7416\n",
      "Epoch 2/20\n",
      "10403/10403 [==============================] - 6s 607us/step - loss: 0.2280 - acc: 0.7369 - val_loss: 0.2169 - val_acc: 0.7486\n",
      "Epoch 3/20\n",
      "10403/10403 [==============================] - 6s 612us/step - loss: 0.2163 - acc: 0.7456 - val_loss: 0.2089 - val_acc: 0.7442\n",
      "Epoch 4/20\n",
      "10403/10403 [==============================] - 6s 606us/step - loss: 0.2047 - acc: 0.7502 - val_loss: 0.2098 - val_acc: 0.7537\n",
      "Epoch 5/20\n",
      "10403/10403 [==============================] - 6s 607us/step - loss: 0.1963 - acc: 0.7533 - val_loss: 0.2100 - val_acc: 0.7399\n",
      "Epoch 6/20\n",
      "10403/10403 [==============================] - 6s 605us/step - loss: 0.1865 - acc: 0.7563 - val_loss: 0.2132 - val_acc: 0.7512\n",
      "Epoch 7/20\n",
      "10403/10403 [==============================] - 6s 597us/step - loss: 0.1766 - acc: 0.7610 - val_loss: 0.2200 - val_acc: 0.7439\n",
      "Epoch 8/20\n",
      "10403/10403 [==============================] - 6s 597us/step - loss: 0.1671 - acc: 0.7637 - val_loss: 0.2207 - val_acc: 0.7491\n",
      "Epoch 9/20\n",
      "10403/10403 [==============================] - 6s 596us/step - loss: 0.1611 - acc: 0.7704 - val_loss: 0.2319 - val_acc: 0.7347\n",
      "Epoch 10/20\n",
      "10403/10403 [==============================] - 6s 616us/step - loss: 0.1529 - acc: 0.7739 - val_loss: 0.2360 - val_acc: 0.7385\n",
      "Epoch 11/20\n",
      "10403/10403 [==============================] - 6s 595us/step - loss: 0.1436 - acc: 0.7758 - val_loss: 0.2563 - val_acc: 0.7512\n",
      "Epoch 12/20\n",
      "10403/10403 [==============================] - 6s 601us/step - loss: 0.1370 - acc: 0.7810 - val_loss: 0.2604 - val_acc: 0.7431\n",
      "Epoch 13/20\n",
      "10403/10403 [==============================] - 6s 606us/step - loss: 0.1287 - acc: 0.7851 - val_loss: 0.2642 - val_acc: 0.7454\n",
      "Epoch 14/20\n",
      "10403/10403 [==============================] - 7s 633us/step - loss: 0.1220 - acc: 0.7899 - val_loss: 0.2836 - val_acc: 0.7390\n",
      "Epoch 15/20\n",
      "10403/10403 [==============================] - 6s 598us/step - loss: 0.1147 - acc: 0.7900 - val_loss: 0.2926 - val_acc: 0.7442\n",
      "Epoch 16/20\n",
      "10403/10403 [==============================] - 6s 596us/step - loss: 0.1094 - acc: 0.7946 - val_loss: 0.2953 - val_acc: 0.7422\n",
      "Epoch 17/20\n",
      "10403/10403 [==============================] - 6s 592us/step - loss: 0.1038 - acc: 0.7945 - val_loss: 0.3126 - val_acc: 0.7457\n",
      "Epoch 18/20\n",
      "10403/10403 [==============================] - 6s 595us/step - loss: 0.0989 - acc: 0.8010 - val_loss: 0.3019 - val_acc: 0.7307\n",
      "Epoch 19/20\n",
      "10403/10403 [==============================] - 6s 590us/step - loss: 0.0910 - acc: 0.8009 - val_loss: 0.3231 - val_acc: 0.7419\n",
      "Epoch 20/20\n",
      "10403/10403 [==============================] - 6s 597us/step - loss: 0.0870 - acc: 0.8059 - val_loss: 0.3257 - val_acc: 0.7287\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(pad_vec_data(corpus), labels)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "test_x = np.array(test_x)\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "gc.collect()\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          shuffle=True,\n",
    "          epochs=nb_epochs,\n",
    "          validation_data=(test_x, test_y),\n",
    "#                   verbose=0,\n",
    "          callbacks=[\n",
    "#                       EarlyStopping(min_delta=0.000025, patience=10),\n",
    "          ])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE: hello there, my name is mike [0.07703983 0.9229602 ]\n",
      "POSITIVE: not something i wanted to happen but i think i need to add more words for it to see [0.55461526 0.44538477]\n",
      "POSITIVE: this was something i wanted i'm grateful for this app and i am looking forward to more things from you guys [0.5571791  0.44282088]\n",
      "NEGATIVE: i don't fucking like you man [0.20254856 0.7974514 ]\n",
      "POSITIVE: considering how the usual process for this is tedious, having an app like this solves a lot of problems [0.997552   0.00244804]\n",
      "POSITIVE: thank you that was some wonderful service that really helped me get from point A to point B [0.6481324  0.35186765]\n",
      "POSITIVE: this is amazing and was able to shorten the amount of time i needed to take to achieve this [0.9417186  0.05828135]\n",
      "POSITIVE: this is nothing short of amazing, I cannot believe it [0.9563106  0.04368946]\n",
      "NEGATIVE: how are you [0.25976652 0.7402335 ]\n",
      "NEGATIVE: i really like you [0.00593156 0.9940685 ]\n",
      "NEGATIVE: i don't actually like this product! [0.00628234 0.9937177 ]\n",
      "NEGATIVE: it's useless if you can't use it! [0.00305249 0.99694747]\n",
      "NEGATIVE: i can't believe i never heard of this [0.00636073 0.9936393 ]\n",
      "POSITIVE: this is awesome, didn't know I needed this [0.74204475 0.25795528]\n",
      "NEGATIVE: so what am i supposed to use this for? [0.00294129 0.99705875]\n",
      "NEGATIVE: what do I need this for? [0.10578904 0.89421093]\n",
      "NEGATIVE: this is good [0.48384374 0.51615626]\n",
      "NEGATIVE: this is not good [0.48384374 0.51615626]\n",
      "POSITIVE: although the movie was great, it lacked impact [0.53489697 0.46510303]\n",
      "NEGATIVE: the movie wasnt that nice [0.03433315 0.9656669 ]\n",
      "NEGATIVE: the movie was nice [0.00999815 0.9900018 ]\n",
      "POSITIVE: this is not acceptable, I lost everything using your app [0.7734799  0.22652014]\n",
      "POSITIVE: that was kinda stupid [0.531975   0.46802503]\n",
      "POSITIVE: the instructions were unlear and is not friendly for non-techy people [0.9802624  0.01973759]\n",
      "NEGATIVE: this is really useful i would definitely tell everyone about it [0.04797158 0.9520284 ]\n",
      "NEGATIVE: i need to try this! [0.00236291 0.99763715]\n",
      "POSITIVE: which is your favourite harry potter filmsorcerers stonechamber of secretsprisoner of azkabangoblet of firei like them all equallyi hate harry potter and think this is a stupid question [0.88897943 0.1110206 ]\n",
      "NEGATIVE: sitting in the third row of the imax cinema at sydney s darling harbour  but i sometimes felt as though i was in the tiny two seater plane that carried the giant camera around australia  sweeping and gliding  banking and hovering over some of the most not [0.01238191 0.9876181 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mess = [\n",
    "    \"hello there, my name is mike\",\n",
    "    \"not something i wanted to happen but i think i need to add more words for it to see\",\n",
    "    \"this was something i wanted i'm grateful for this app and i am looking forward to more things from you guys\",\n",
    "    \"i don't fucking like you man\",\n",
    "    \"considering how the usual process for this is tedious, having an app like this solves a lot of problems\",\n",
    "    \"thank you that was some wonderful service that really helped me get from point A to point B\",\n",
    "    \"this is amazing and was able to shorten the amount of time i needed to take to achieve this\",\n",
    "    \"this is nothing short of amazing, I cannot believe it\",\n",
    "    \"how are you\",\n",
    "    \"i really like you\",\n",
    "    \"i don't actually like this product!\",\n",
    "    \"it's useless if you can't use it!\",\n",
    "    \"i can't believe i never heard of this\",\n",
    "    \"this is awesome, didn't know I needed this\",\n",
    "    \"so what am i supposed to use this for?\",\n",
    "    \"what do I need this for?\",\n",
    "    \"this is good\",\n",
    "    \"this is not good\",\n",
    "    \"although the movie was great, it lacked impact\",\n",
    "    \"the movie wasnt that nice\",\n",
    "    \"the movie was nice\",\n",
    "    \"this is not acceptable, I lost everything using your app\",\n",
    "    \"that was kinda stupid\",\n",
    "    \"the instructions were unlear and is not friendly for non-techy people\",\n",
    "    \"this is really useful i would definitely tell everyone about it\",\n",
    "    \"i need to try this!\",\n",
    "    \"which is your favourite harry potter filmsorcerers stonechamber of secretsprisoner of azkabangoblet of firei like them all equallyi hate harry potter and think this is a stupid question\",\n",
    "    \"sitting in the third row of the imax cinema at sydney s darling harbour  but i sometimes felt as though i was in the tiny two seater plane that carried the giant camera around australia  sweeping and gliding  banking and hovering over some of the most not\",\n",
    "]\n",
    "\n",
    "pred = model.predict(pad_vec_data(list(map(remove_stop_words, mess))))\n",
    "output = ''\n",
    "\n",
    "for i ,m in enumerate(mess):\n",
    "    output += ('{} {} {}\\n'.format('POSITIVE:' if pred[i][0] > 0.5 else 'NEGATIVE:', m, pred[i]))\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
