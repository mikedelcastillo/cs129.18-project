{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from nltk.corpus import stopwords\n",
    "np.random.seed(1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only' 'y' 'by' 'am' 'most' 'me' 'same' 'these' 'so' 'some' 'why' 'down'\n",
      " 'had' 'd' 'at' 'having' 'those' 'has' 'few' 'theirs' \"you've\" 'more' 'i'\n",
      " 'than' 'through' 'be' 'what' 'where' 'myself' 'which' 'doing' 'ours'\n",
      " 'will' 'in' 'both' 'do' 'it' 'o' 'on' 'yours' 'once' 'ourselves' 'here'\n",
      " 'about' \"it's\" 'my' 'for' 'her' 'then' 'after' \"should've\" 'from' 'each'\n",
      " 'when' 'does' 'now' 'off' 'don' 'are' 'we' 'itself' 'should' 'his'\n",
      " 'between' 'our' 'were' 'under' 'other' 'all' 'she' 'won' 'been' \"you're\"\n",
      " 'how' 'did' 'yourself' 'they' 'into' 'there' 've' 'such' 't' 's' 'and'\n",
      " 'over' 'to' 'just' 'was' 'being' 'because' 'if' 'who' 'further' 'the'\n",
      " 'any' \"that'll\" 'themselves' 'as' 'again' \"you'd\" 'until' 'he' 'him'\n",
      " 'this' 'or' 'of' 'below' 'an' \"she's\" 'weren' 'm' 'their' 'ma' 'up' 'll'\n",
      " 'whom' 'hers' 'can' 'you' 'them' 'very' 'a' 'herself' 'before' 'too'\n",
      " 'himself' 'during' 're' 'out' 'its' 'above' 'own' 'have' 'while'\n",
      " 'yourselves' 'that' 'with' \"you'll\" 'is' 'your']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "stop_words = pd.read_csv('../data/stopwords.csv')['words'].values\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    word_tokens = text_to_word_sequence(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/twitter-airline-sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials experience tacky</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>didnt today must mean need take another trip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos  neg\n",
       "0                                               said  0.0  0.0\n",
       "1      plus youve added commercials experience tacky  1.0  0.0\n",
       "2       didnt today must mean need take another trip  0.0  0.0\n",
       "3  really aggressive blast obnoxious entertainmen...  0.0  1.0\n",
       "4                               really big bad thing  0.0  1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = list(map(remove_stop_words, data['text'].values))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data['text'].values\n",
    "corpus = [text_to_word_sequence(y) for y in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw_train, X_raw_test, Y_train, Y_test = train_test_split(\n",
    "    sentences,\n",
    "    data[['pos', 'neg']].values,\n",
    "    test_size=0.2, \n",
    "    random_state=3945\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 35\n",
    "vector_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "word2vec = Word2Vec(sentences=corpus,\n",
    "                    size=vector_size, \n",
    "                    window=10, \n",
    "                    negative=20,\n",
    "                    iter=50,\n",
    "                    seed=1000,\n",
    "                    workers=4)\n",
    "word2vec = word2vec.wv\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2index(corpus):\n",
    "    gc.collect()\n",
    "    input_matrix = np.zeros((len(corpus),max_sentence_length))\n",
    "    \n",
    "    for i in range(len(corpus)):\n",
    "        for t, token in enumerate(corpus[i]):\n",
    "            if t >= max_sentence_length:\n",
    "                break\n",
    "            if token not in word2vec.vocab:\n",
    "                continue\n",
    "            input_matrix[i, t] = word2vec.vocab.get(token).index\n",
    "    return input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sent2index(X_raw_train)\n",
    "X_test = sent2index(X_raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2590, 300)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "vocab_len = len(word2vec.vocab) + 1\n",
    "\n",
    "emb_matrix = np.zeros((vocab_len, vector_size))\n",
    "\n",
    "for word in word2vec.vocab:\n",
    "    index = word2vec.vocab.get(word).index\n",
    "    emb_matrix[index, :] = word2vec[word]\n",
    "    \n",
    "print(emb_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "sentence_indices = Input(shape=(max_sentence_length,))\n",
    "    \n",
    "embedding_layer = Embedding(vocab_len, vector_size, trainable = False)\n",
    "embedding_layer.build((None,))\n",
    "embedding_layer.set_weights([emb_matrix])\n",
    "\n",
    "embeddings = embedding_layer(sentence_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 35, 300)           777000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 35, 128)           219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,128,490\n",
      "Trainable params: 351,490\n",
      "Non-trainable params: 777,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X = LSTM(128, return_sequences=True)(embeddings)\n",
    "X = Dropout(0.5)(X)\n",
    "X = LSTM(128, return_sequences=False)(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Dense(2, activation=None)(X)\n",
    "X = Activation('softmax')(X)\n",
    "\n",
    "model = Model(inputs=[sentence_indices], outputs=X)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11096 samples, validate on 2775 samples\n",
      "Epoch 1/20\n",
      "11096/11096 [==============================] - 49s 4ms/step - loss: 0.3930 - acc: 0.6389 - val_loss: 0.3884 - val_acc: 0.6256\n",
      "Epoch 2/20\n",
      "11096/11096 [==============================] - 48s 4ms/step - loss: 0.3827 - acc: 0.6395 - val_loss: 0.3816 - val_acc: 0.6256\n",
      "Epoch 3/20\n",
      "11096/11096 [==============================] - 62s 6ms/step - loss: 0.3733 - acc: 0.6435 - val_loss: 0.3647 - val_acc: 0.6303\n",
      "Epoch 4/20\n",
      "11096/11096 [==============================] - 51s 5ms/step - loss: 0.3615 - acc: 0.6465 - val_loss: 0.3660 - val_acc: 0.6324\n",
      "Epoch 5/20\n",
      "11096/11096 [==============================] - 46s 4ms/step - loss: 0.3509 - acc: 0.6493 - val_loss: 0.3538 - val_acc: 0.6306\n",
      "Epoch 6/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.3368 - acc: 0.6568 - val_loss: 0.3420 - val_acc: 0.6396\n",
      "Epoch 7/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.3272 - acc: 0.6627 - val_loss: 0.3375 - val_acc: 0.6670\n",
      "Epoch 8/20\n",
      "11096/11096 [==============================] - 45s 4ms/step - loss: 0.3200 - acc: 0.6713 - val_loss: 0.3471 - val_acc: 0.6479\n",
      "Epoch 9/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.3127 - acc: 0.6738 - val_loss: 0.3415 - val_acc: 0.6526\n",
      "Epoch 10/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.3065 - acc: 0.6805 - val_loss: 0.3349 - val_acc: 0.6695\n",
      "Epoch 11/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.2976 - acc: 0.6843 - val_loss: 0.3458 - val_acc: 0.6605\n",
      "Epoch 12/20\n",
      "11096/11096 [==============================] - 42s 4ms/step - loss: 0.2896 - acc: 0.6931 - val_loss: 0.3587 - val_acc: 0.6483\n",
      "Epoch 13/20\n",
      "11096/11096 [==============================] - 44s 4ms/step - loss: 0.2860 - acc: 0.6892 - val_loss: 0.3291 - val_acc: 0.6728\n",
      "Epoch 14/20\n",
      "11096/11096 [==============================] - 42s 4ms/step - loss: 0.2779 - acc: 0.6984 - val_loss: 0.3337 - val_acc: 0.6595\n",
      "Epoch 15/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.2690 - acc: 0.7034 - val_loss: 0.3438 - val_acc: 0.6580\n",
      "Epoch 16/20\n",
      "11096/11096 [==============================] - 42s 4ms/step - loss: 0.2624 - acc: 0.7088 - val_loss: 0.3470 - val_acc: 0.6703\n",
      "Epoch 17/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.2563 - acc: 0.7094 - val_loss: 0.3427 - val_acc: 0.6710\n",
      "Epoch 18/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.2465 - acc: 0.7167 - val_loss: 0.3522 - val_acc: 0.6674\n",
      "Epoch 19/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.2394 - acc: 0.7183 - val_loss: 0.3576 - val_acc: 0.6706\n",
      "Epoch 20/20\n",
      "11096/11096 [==============================] - 43s 4ms/step - loss: 0.2300 - acc: 0.7231 - val_loss: 0.3736 - val_acc: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a407ac39e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y=Y_train, \n",
    "    batch_size=32, \n",
    "    epochs=20, \n",
    "    verbose=1, \n",
    "    validation_data=(X_test, Y_test), \n",
    "#     callbacks=[earlystop],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEGATIVE: this is slow [0.30715123 0.6928488 ]\n",
      "POSITIVE: this is exceptional service [0.9860232  0.01397681]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mess = np.array([\n",
    "    'this is slow',\n",
    "    'this is exceptional service',\n",
    "])\n",
    "X_test_indices = sent2index(mess)\n",
    "pred = model.predict(X_test_indices)\n",
    "\n",
    "output = ''\n",
    "for i ,m in enumerate(mess):\n",
    "        output += ('{} {} {}\\n'.format('POSITIVE:' if pred[i][0] > 0.5 else 'NEGATIVE:', m, pred[i]))\n",
    "        \n",
    "print(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
