{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['only' 'y' 'by' 'am' 'most' 'me' 'same' 'these' 'so' 'some' 'why' 'down'\n",
      " 'had' 'd' 'at' 'having' 'those' 'has' 'few' 'theirs' \"you've\" 'more' 'i'\n",
      " 'than' 'through' 'be' 'what' 'where' 'myself' 'which' 'doing' 'ours'\n",
      " 'will' 'in' 'both' 'do' 'it' 'o' 'on' 'yours' 'once' 'ourselves' 'here'\n",
      " 'about' \"it's\" 'my' 'for' 'her' 'then' 'after' \"should've\" 'from' 'each'\n",
      " 'when' 'does' 'now' 'off' 'don' 'are' 'we' 'itself' 'should' 'his'\n",
      " 'between' 'our' 'were' 'under' 'other' 'all' 'she' 'won' 'been' \"you're\"\n",
      " 'how' 'did' 'yourself' 'they' 'into' 'there' 've' 'such' 't' 's' 'and'\n",
      " 'over' 'to' 'just' 'was' 'being' 'because' 'if' 'who' 'further' 'the'\n",
      " 'any' \"that'll\" 'themselves' 'as' 'again' \"you'd\" 'until' 'he' 'him'\n",
      " 'this' 'or' 'of' 'below' 'an' \"she's\" 'weren' 'm' 'their' 'ma' 'up' 'll'\n",
      " 'whom' 'hers' 'can' 'you' 'them' 'very' 'a' 'herself' 'before' 'too'\n",
      " 'himself' 'during' 're' 'out' 'its' 'above' 'own' 'have' 'while'\n",
      " 'yourselves' 'that' 'with' \"you'll\" 'is' 'your']\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "stop_words = pd.read_csv('../data/stopwords.csv')['words'].values\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    word_tokens = text_to_word_sequence(text) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing see not works hooray'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words(\"testing to see if this will not works hooray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/twitter-airline-sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>said</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus youve added commercials experience tacky</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>didnt today must mean need take another trip</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pos  neg\n",
       "0                                               said  0.0  0.0\n",
       "1      plus youve added commercials experience tacky  1.0  0.0\n",
       "2       didnt today must mean need take another trip  0.0  0.0\n",
       "3  really aggressive blast obnoxious entertainmen...  0.0  1.0\n",
       "4                               really big bad thing  0.0  1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = list(map(remove_stop_words, data['text'].values))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = GaussianNB()\n",
    "classifier = RandomForestClassifier()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "            np.array(data.text), \n",
    "            np.array(data.pos),\n",
    "            test_size=0.2, \n",
    "            random_state=3945)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train_x = vectorizer.fit_transform(train_x)\n",
    "classifier.fit(tfidf_train_x.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.73 percent\n"
     ]
    }
   ],
   "source": [
    "tfidf_test_x = vectorizer.transform(test_x)\n",
    "scores = cross_val_score(classifier, tfidf_test_x.toarray(), test_y, cv=5)\n",
    "acc = scores.mean()\n",
    "print(\"Accuracy: %0.2f percent\" % (acc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woah that  ==  0.0  hmm  [0.88958668 0.11041332]\n",
      "fuck that  ==  0.0  hmm  [0.88958668 0.11041332]\n",
      "i think it was fine but that shit was horrible!  ==  0.0  hmm  [1. 0.]\n",
      "meg how are you?  ==  0.0  hmm  [0.88958668 0.11041332]\n",
      "i really did not like this!  ==  0.0  hmm  [1. 0.]\n",
      "i hated this  ==  0.0  hmm  [0.88958668 0.11041332]\n",
      "that's not really nice  ==  0.0  hmm  [0.6 0.4]\n",
      "i'm not into you  ==  0.0  hmm  [1. 0.]\n",
      "i want to try things out  ==  0.0  hmm  [0.88833333 0.11166667]\n",
      "i really think this will work out great!  ==  0.0  hmm  [0.74047619 0.25952381]\n",
      "this was great!  ==  0.0  hmm  [0.74285714 0.25714286]\n",
      "this was not great!  ==  1.0  hmm  [0.40952381 0.59047619]\n",
      "i didn't get how it worked? what is wrong?  ==  1.0  hmm  [0.4 0.6]\n",
      "your service is subpar  ==  0.0  hmm  [0.99285714 0.00714286]\n",
      "service  ==  0.0  hmm  [0.99285714 0.00714286]\n",
      "good  ==  0.0  hmm  [0.9 0.1]\n",
      "bad  ==  0.0  hmm  [1. 0.]\n",
      "hate  ==  0.0  hmm  [0.98297872 0.01702128]\n",
      "love  ==  1.0  hmm  [0.025 0.975]\n"
     ]
    }
   ],
   "source": [
    "mess = [\n",
    "    'woah that', \n",
    "    'fuck that',\n",
    "    'i think it was fine but that shit was horrible!',\n",
    "    'meg how are you?',\n",
    "    'i really did not like this!',\n",
    "    'i hated this',\n",
    "    \"that's not really nice\",\n",
    "    \"i'm not into you\",\n",
    "    \"i want to try things out\",\n",
    "    \"i really think this will work out great!\",\n",
    "    \"this was great!\",\n",
    "    \"this was not great!\",\n",
    "    \"i didn't get how it worked? what is wrong?\",\n",
    "    \"your service is subpar\",\n",
    "    \"service\",\n",
    "    \"good\",\n",
    "    \"bad\",    \n",
    "    \"hate\",\n",
    "    \"love\",\n",
    "\n",
    "]\n",
    "t = vectorizer.transform(list(map(remove_stop_words, mess))).toarray();\n",
    "output = classifier.predict(t)\n",
    "proba = classifier.predict_proba(t)\n",
    "\n",
    "for i ,m in enumerate(mess):\n",
    "    print(m, ' == ', output[i], ' hmm ', proba[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "import urllib, json\n",
    "import urllib.request\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "TLGRM_SECRET = os.getenv('TLGRM_SECRET')\n",
    "TLGRM_MIKE = os.getenv('TLGRM_MIKE')\n",
    "\n",
    "def telegram_call(method, query = {}):\n",
    "    url = 'http://api.telegram.org/bot{}/{}?{}'.format(TLGRM_SECRET, method, urllib.parse.urlencode(query))\n",
    "    response = urllib.request.urlopen(url)\n",
    "    return json.loads(response.read().decode(\"utf-8\"))\n",
    "\n",
    "def telegram_bot(respond):\n",
    "    last_offset = 0\n",
    "    \n",
    "    while True:\n",
    "        data = telegram_call('getupdates', {'offset': last_offset})\n",
    "        for item in data['result']:\n",
    "            last_offset = item['update_id'] + 1\n",
    "            if 'message' in item:\n",
    "                if 'text' in item['message']:\n",
    "                    text = item['message']['text']\n",
    "                    chat_id = item['message']['chat']['id']\n",
    "                    response = respond(text)\n",
    "                    telegram_call('sendmessage', {\n",
    "                        'chat_id': chat_id,\n",
    "                        'text': response\n",
    "                    })\n",
    "\n",
    "                    print('FROM: {}\\nSAYS: {}\\nRESPONSE: {}\\n\\n'.format(chat_id, text, response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM: -221717641\n",
      "SAYS: i think this will work find\n",
      "RESPONSE: 0.0\n",
      "\n",
      "\n",
      "FROM: -221717641\n",
      "SAYS: fine\n",
      "RESPONSE: 0.0\n",
      "\n",
      "\n",
      "FROM: -221717641\n",
      "SAYS: exceptional service\n",
      "RESPONSE: 1.0\n",
      "\n",
      "\n",
      "FROM: -221717641\n",
      "SAYS: this is too slow\n",
      "RESPONSE: 0.0\n",
      "\n",
      "\n",
      "FROM: -221717641\n",
      "SAYS: i am happy about this service\n",
      "RESPONSE: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def respond(text):\n",
    "    mess = [text]\n",
    "    t = vectorizer.transform(list(map(remove_stop_words, mess))).toarray();\n",
    "    output = classifier.predict(t)\n",
    "    proba = classifier.predict_proba(t)\n",
    "    \n",
    "    return '{}'.format(output[0])\n",
    "\n",
    "telegram_bot(respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
